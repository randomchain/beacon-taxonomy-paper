% Randomness beacons
\section{Randomness Beacons}
%   What is a beacon?
In the context of this paper, we define a beacon as an entity, which publishes some data, at a regular known interval.
This constant stream of data is the opposite of \emph{on-demand}, which does not have a set interval, and must be triggered to output data.
A \emph{randomness} beacon is therefore defined as some entity publishing \emph{random} data, at a regular known interval.
Formally, let $B: f(I_t) \rightarrow R$, where $B$ is a beacon, $I_t$ is the input at time $t$ and $f$ is some computation, then $R$ is the random outcome.
For $B$ to be a beacon it is then run at every $t_\Delta$ time interval, with new input $I_t$.
The function $f$ can be an extractor function, which takes some input $x$ and outputs $y$, trading length of output for a higher level of entropy.
Extractor functions and their properties are further explained by \citet{bonneau2015bitcoin}.\msmnote{maybe expand on extractor functions in some Entropy section?}

The definition of a \emph{randomness beacon} does not specify any properties about, interaction, security, nor execution of the beacon and its protocol.
These properties rely on the setting and requirements of a given beacon.
However, all randomness beacon approaches must address the following specifications.

\subsection{Specifications of a Randomness Beacon}
%   Beacon specifications
When dealing with specifications of a randomness beacon, we focus on two main perspectives, namely \emph{security objectives}, and \emph{trust assumptions}.
These describe what a randomness beacon must take into account regarding security and attacks, and what assumptions can be made about the trustworthiness of said beacon.
Security and trust are two sides of the same coin, which means that the approach a given beacons takes to handling the security objectives will influence and define the trust assumptions about it;
but also that a beacon aiming for a given set of trust assumptions, must implement specific security measures.
%       Security objectives
\subsubsection{Security Objectives}\label{ssub:security_objectives}
For randomness beacons there exists two prevalent concepts when it comes to security objectives: \emph{availability} and \emph{integrity}.
Each term embodies multiple attacks and requirements for fulfillment, however, different randomness beacon approaches assigns different priorities to these.

\begin{description}

    \item[Availability:]
        Attacks on the availability essentially prevent a set of users from being able to gain access to a given randomness beacon.
        This can be both their ability to contribute with input, or discover the output.
        In scenarios where the beacon is driven by a single entity, attacking the availability can also mean preventing the beacon from collecting input or publishing the outcome, thereby effectively denying service for all potential users.
        Besides attacks, bugs in the implementation or network failures can result in degraded availability;
        generally these vulnerabilities are present in the same scenarios as direct attacks.
        Therefore, a randomness beacon prioritizing availability, can choose to focus on robustness, redundancy, and failover, to mitigate failures and attacks on availability.

        Examples of concrete attacks on the availability of a randomness beacon are:
        \acrfull{dos} where an attacker overwhelms the beacon with e.g.\ input, thereby making any other user unable to supply entropy as input. A \gls{dos} attack could also be on the availability of the source of input itself; eclipse attacks where an attacker eclipses a part of the network, thus only making the beacon unavailable to some select users.

    \item[Integrity:]
        The integrity of a randomness beacon, determines whether a given user should trust the outcome and to what degree.
        Attacking the integrity is therefore, any attack which compromises the outcome of a randomness beacon.
        This can mean manipulating the input/entropy to the beacon, but also compromising the entire computation and outcome;
        as beacons can be seen as entities and not a particular actor, one might imagine a scenario where an attacker imposes themselves as the beacon.
        As with availability, the integrity can also be influenced by bugs in the implementation.
        Moreover, if the implementation is closed sources / proprietary, the beacon loses transparency and the integrity will be questionable at best.

        Attacks on the integrity could be: successfully supplying valid input, which is able to bias the outcome, e.g.\ last draw attacks, where an adversary supplies the last input and therefore potentially is able to choose some input beneficial to them;
        if the operator of the beacon is malicious, they might be able to generate a seemingly fair and random outcome by corrupting the computation of the beacon.

        The integrity also relies on the beacon being unpredictable, i.e.\ no adversary should be able to predict the outcome before it is too late to manipulate it.
        Finally, integrity also embodies the fact that the outcome should be unbiased and uniformly distributed; any detectable statistical bias should be negligible.

\end{description}

%       Trust assumptions
\subsubsection{Trust Assumptions}\label{ssub:trust_assumptions}
As stated previously, the prioritization of the aforementioned security objectives establishes the assumptions one can make about the trustworthiness of a randomness beacon.
Moreover, the trust assumptions also depend on the interaction with, and execution of the beacon, as well as the source of entropy of the beacon.
The following trust assumptions are from a users point of view, unless otherwise stated.
A user is anyone with a stake in the outcome of the beacon, both through direct use, but also indirect/inferred usage.
\begin{description}

    \item [Guaranteed Entropy Level:]
        Assumptions about the level of entropy in the outcome, relies on the entropy of the input and the properties of the computation which generates the outcome, e.g.\ an extractor function.
        Firstly, this means that the functions used to compute the outcome should be publicly available, such that anyone will be able to verify that the level of entropy is not degraded.
        Secondly, the user must be able to reason about the entropy level of the input.

    \item [Verifiability:]
        For a beacon to display verifiability, any user must be able to verify correct execution of the beacon protocol.
        This includes being able to check input sources to the randomness beacon;
        consequently the input to the beacon must be available for it to be verifiable, unless the beacon is able to produce a proof, which then allows users to verify with zero-knowledge \msmnote[nofootnote, inline]{this could be interesting to expand upon, to allow for anonymized beacon interaction}.

        The most straight forward process of verification for randomness beacons, is the ability for anyone to run the same computation on the same input.
        However, in some cases this may be impractical or the input should remain secret; thereby calling for another approach to proofing validity of the outcome.

        An example of verifiability outside beacons, is in the blockchain, where the validity of a block can be verified by anyone, using the block itself and a \acrfull{sha}.
        Here the verifiability removes the need to trust any participating miners in the blockchain.

        Verifiability can eliminate the need for trust in participants, while ensuring the trustworthiness of the outcome.

    \item [Input Reasoning:]
        Being able to reason about the input is somewhat coupled to the two previous trust assumptions.
        But assuming that we can trust the entropy level of the input, what assumptions are users able to make about the bias of the input.
        This mainly relates to beacons where the input is supplied by users, i.e.\ users which does not necessarily trust each other.

        A given user might not need to worry about the input, even if everybody else is colluding against said user.
        This is true in a scenario where said user is able to contribute with their own input, and the beacon's computation is fair
        --- i.e.\ no one user's input affects the outcome differently.

\end{description}

%   Settings for beacons:
\subsection{Settings for Randomness Beacons}
Since a randomness beacon is a versatile and broad concept, it can be deployed in a myriad of vastly different settings.
These settings all alter the way the beacon operates and how users interact with it.
Furthermore, it affects which shape the beacon implementation takes, i.e.\ different technologies fits in varying settings.

There are two main distinctions when dealing with settings of a randomness beacon --- \emph{private} and \emph{public}.
Within these categories are then different views on trust, scalability, intent, and incentives.

\begin{description}
    \item[Private:]
        In a private setting it is safe to assume that no participant will be obviously malicious, i.e.\ an adversary will not risk being caught rred-handed since it would exclude him from the network.
        However, we can suspect that an adversary will try to manipulate the outcome of a randomness beacon if possible --- all users are anticipated to seek whatever benefits themselves.
        This means that all detectable manipulation and malicious activities will be avoided by the participants of the private network.

        We also assume that the continuous operation of a randomness beacon is a requirement for the private network, which means that all participants has an incentive to ensure timely execution.
        Unless a participant can benefit from the beacon not outputting, in which case they might simulate e.g.\ network issues to abrupt the beacon if possible.

        Scalability might be an issue in larger private networks, however, generally private networks are sufficiently small such that scaling is not a concern.
    \item[Public:]
        All bets are off, when in comes to public networks, such as the internet.
        Here we can assume that all participants will try to manipulate the beacon outcome to their advantage, no matter the cost.
        Whether they have the resources available to do so, is besides the point.
        Likewise, any individual user might also in some cases suspect that all other users are colluding against them.

        In the public setting, it might not be all participants that have a stake in the randomness beacon operating constantly.
        Therefore, it is important to have established incentives for both users to use the beacon, but also for the execution of the beacon protocol.

        Because public settings are almost infinitely large, i.e.\ any user should be able to join, scalability is a key concern --- availability requires scalability.
\end{description}

%   Properties of beacons
\subsection{Properties of Randomness Beacons}
Based on the specifications and different settings, we define three sets of properties, which can be compiled to describe different types of randomness beacons.
These sets of properties cover \emph{entropy sourcing}, \emph{execution model}, and \emph{validation}.
In the later taxonomy of current randomness beacons approaches, these properties will also be used for classification.

%       Entropy sourcing
\subsection{Entropy Sourcing}
The input of a randomness beacon at a given time, $I_t$, is essentially the grounds for the entropy of the outcome.
The following three points describe different ways for a randomness beacon to source the input, i.e.\ entropy.
\begin{description}
    \item[User Input:]
        The protocol allows users to provide entropy.
        This can open up for direct manipulation of the result by last-draw attacks, if not handled properly.
        If user input is the only source of entropy, lack of users denies availability of the beacon's outcome, and thereby availability of the randomness beacon.

        User input can potentially become a bottleneck depending on the number of users wanting to supply randomness.
        This can result in input sourcing cutoff, which means that not all user inputs will be used in the computation of the outcome, thereby tarnishing those users' ability to trust the given iteration of the beacon.

    \item[Private External Input:]
        Using external input such as background radiation and output from photon splitters.
        These sources are often of significantly high entropy, however, difficult if not impossible to reproduce and verify for users.
        Moreover, it is virtually impossible for users of the beacon to reason about the validity of the input; hence complete trust in the honesty of the beacon operator is required.

    \item[Publicly Available External Input:]
        For input to be publicly available, it must be accessible to the public, and consistent over a period.
        These sources can be the blockchain, financial data, or national lottery results.

        Anyone who wishes to manipulate it must do it through the external source.
        An external source, which the public can influence might be susceptible to an adversary trying to bias the beacon outcome, therefore it is important to analyse the integrity of the external source when looking at the integrity of the randomness beacon itself.

        It is important to note that publicly available external input does not make the outcome predictable --- i.e.\ an adversary will not be able to predict the beacon outcome before it is expected to be know.
        Furthermore, any user of the beacon will be able to verify that the acclaimed input has been used to generate the outcome.

\end{description}

%       Execution model
\subsection{Execution Model}
Once entropy is obtained, some computation is performed, $f(I_t)$, to ensure the entropy level and uniform distribution of the outcome.
We identify the following ways of executing such a computation in a randomness beacon protocol:

\begin{description}
    \item[Self-Announced Entity:]
        The protocol is computed by a central entity who provides a service in form of a complete beacon.
        This type of execution requires verifiability or complete trust in the central entity.

        The entity, while self-announced, can be driven by a community, authority, or single person, but is always controlled by the same entity.
        Availability is a major concern with this type of execution, since it imposes a single-point-of-failure, if not for computation then for trust.

    \item[Elected Operator:]
        A user is collectively elected to be the operator which performs the computation.
        That user then executes the beacon protocol as a public good.
        This type of execution participation requires that the operator has an incentive to carry out the beacon protocol, and may hurt availability if the operator leaves their role.

    \item[Distributed Execution:]
        The computation of the protocol is done in a distributed manner between a set of parties e.g.\ using \gls{mpc} and/or smart contracts.
        This model does potentially not require trust in any other participant depending on the execution scheme.
        However, scalability to larger settings may prove difficult, and participants with byzantine behaviour must be accounted for, which can hurt availability.

    \item[Self-Service Execution:]
        Each user performs the same execution to obtain a random value.
        This model does not require trust in the execution participants, but requires trust in the input entropy, and last-draw attacks and manipulating can become prevalent with potential predictability if using user input.
        Computational resources are only consumed by participants with a stake in the beacon output.
\end{description}

%       Validation
\subsection{Validation}
The output of the computation in the randomness beacon need some form of validation in order to be trustworthy.
We identify the following ways of performing this validation:

\begin{description}
    \item[Verifiable:]
        A user can verify the randomness to have been correctly computed from the provided entropy.
        This is directly related to the verifiability in the aforementioned trust assumptions.

    \item[Contestable:]
        Users can contest the randomness of the beacon if they believe it to be wrong.
        The beacon operator must then prove the correctness or incur some penalty, while a user that successfully contests the beacon is rewarded. \mtjnote[nofootnote,inline]{This will be futher elaborated}
\end{description}

%   Beacon types
\subsection{Types of Randomness Beacon}
We present some archetypes of randomness beacons derived from combinations of the above properties.
Moreover, we briefly describe the main strengths and weaknesses for each archetype.
They will later be related to approaches in the taxonomy of current randomness beacons.

\subsubsection{Autocratic Collector}\label{ssub:autocratic}
The most naïve implementation of a randomness beacon, is an autocratic beacon, which collects input from an external private source.
This means that a single entity governs the randomness beacon with complete authority, meaning that no transparency is required.
Randomness beacons of this type are highly scalable, since a multiple instance setup only needs coordination with itself.
Moreover, there is no bottleneck in collecting entropy as input, since it only relies on measuring something in the real world e.g.\ background radiation.

However, autocratic beacons are untrustworthy in nature, since the entity has total self-governing.
There is no validation present in this type, it is neither verifiable nor contestable, not even if the input entropy is published as proof.
This is because the private external input source which itself cannot be verified by users.

A well-known analogue of a \emph{autocratic collector} beacon is a web blog.
Here, the author/administrator of the blog is in total control of the content of the blog.
They may claim that the input/background of the posts stems from somewhere, but there is usually not way of validating this claim.
As a reader you have to trust the author, as a user of this beacon type has to trust the governing entity.

\subsubsection{Specialized \gls{mpc}}\label{ssub:specialized_mpc}
To alleviate the need for absolute trust in the beacon operator, a beacon protocol utilizing \acrfull{mpc} can be deployed.
This eliminates the need for trust between individual participants.
A beacon of this type will source its entropy from user input during the execution of the \gls{mpc} beacon protocol.
The randomness outcome can therefore be trusted by any user to be unbiased, if and only if said user participated in the \gls{mpc} protocol.
Effectively this means that while this type does not require absolute trust it requires absolute participation --- all users wanting a trustworthy outcome must participate.

As a consequence, the availability can be severely hindered if one or multiple adversaries decides to drop out mid-execution.
Because of this, a specialized \gls{mpc} beacon is best suited for a private setting, where we can assume that participants will carry out the computation, and ban anyone who tries to corrupt the beacon.

Scaling \gls{mpc} protocols, can also be cumbersome if not outright impossible, especially in relation to a beacon, where the outcome is required to be published at a given time.

\subsubsection{Transparent Authority}\label{ssub:transparent_authority}
As a middle ground between the two previous beacon archetype, the transparent authority beacon, aims to provide both scalability, availability and trustworthiness.
This is probable since the beacon displays transparency in both entropy sourcing and execution, i.e.\ using publicly available external or user generated input, and enabling validation of the execution and outcome.
However, the transparency of the authority behind the beacon can still be a self-announced entity, as long as validation is possible, the execution model is irrelevant.

If the execution of the beacon protocol is to be done by a single entity, it is important to have a solid incentive for running it --- as well as an incentive for the operator to be honest.
This can be as simple as a community funded entity serving a \enquote{public good} as discussed by \citet{bunz2017proofsof}.

Because this beacon type uses publicly available or user generated input, entropy source manipulation from adversaries must be taken into account --- often resolving in a probabilistic trust assumption, where the probability of a biased outcome is negligible.

