\subsection{Trust}
When considering trust in randomness beacons, we focus on two main perspectives, namely \emph{trust assumptions} and \emph{attacks}.
These describe what assumptions can be made about the trustworthiness of a randomness beacon, and what attacks must be considered.
Trust and attacks are two sides of the same coin, which means that the approach a given beacon takes to handle the attack threats is influenced by and influences the trust assumptions of the beacon.
Not all of these assumptions and attacks will be relevant to all beacons.

\subsubsection{Trust Assumptions}\label{ssub:trust_assumptions}
The trust assumptions of a randomness beacon depend on the interaction with, and execution of the beacon, as well as the source of entropy.
The following trust assumptions are from the users' point of view, unless otherwise stated.
A user is anyone with a stake in the outcome of the beacon, both through direct use, but also indirect or inferred usage.

\paragraph{Guaranteed Entropy}
Assumptions about the level of entropy in the outcome rely on the entropy of the input, $I_t$, and the properties of the computation, $f(I_t)$, which generates the outcome, $O_t$.
Users must be able to reason about the entropy level of the input source through documentation or otherwise.
The entropy source and computation method must be publicly available, such that users can verify the level of entropy.

\paragraph{Verifiability}
For a beacon to be verifiable, a user must be able to verify correct execution of the beacon protocol.
The input to the beacon must be available for users to verify a given output, unless the beacon is able to produce a proof, which allows users to verify.

The most straightforward verification for randomness beacons is for a user to run the same computation on the same input.
This may be impractical or the input may be secret.
Instead the beacon could include proofs or functions that can rapidly be verified such as hash functions~\cite{nakamoto2008bitcoin} or modular square roots~\cite{lenstra2015random}.
Verifiability can eliminate the need to trust participants, while ensuring the trustworthiness of the outcome.

\paragraph{Input Reasoning}
Being able to reason about the input relies on the two previous trust assumptions.
This trust assumption concerns what users can assume about the bias of the input.
The easier it is for adversaries to bias the input, the easier they can bias the randomness.
This assumption may also change significantly if the input is purely user-supplied.
As long a given user contributes their own input, the others may not be able to bias the randomness against him.

\subsubsection{Attacks}\label{ssub:security_objectives}
For randomness beacons there exist two main venues of attack: \emph{availability} and \emph{integrity}.
\emph{Availability} covers users' ability to access and interact with the beacon and its output.
\emph{Integrity} covers the bias of the output and direct manipulation of the beacon.
Each term contains multiple types of attacks and requirements for fulfillment, and will not all be effective versus all beacons. Different randomness beacon approaches assign different priorities to these terms.

We identify the following \gls{dos} attacks on the availability of a beacon:

\begin{description}
    \item[Denial of Input]
For beacons that use user input, the adversary can seek to prevent other users from contributing by overwhelming the beacon or contribution channels.
This allows the adversary to bias the input, which violates the \emph{unpredictable} and \emph{unbiased} properties of the beacon.
While this does not prevent the output, it prevents users from interacting with the beacon according to protocol, hence why it is classified as an attack on availability.

    \item[Preventing Protocol Execution]
Some \gls{mpc} protocols rely on having an honest majority to complete~\cite{cascudo2017scrape} --- an adversary or group of adversaries could outnumber the honest parties, preventing the protocol from delivering an output.

    \item[Denial of Output]
The adversary prevents users from accessing the output by overwhelming the operator with network traffic, or manipulating the network with an eclipse attack~\cite{Singh06eclipseattacks} to prevent certain users from interacting with the beacon.

\end{description}

\noindent%
We also identify the following attacks on the integrity of a beacon:

\begin{description}
    \item[Input Bias Attack]
For beacons that use some external public source for input, an adversary can attempt to bias the results by controlling the source, violating the unpredictability of the beacon.
The difficulty of this type of attack depends on the malleability of the input.
    \item[Last Draw Attack]
In beacons using multiple inputs, one of these inputs will be the last input before the beacon generates the output.
A last draw attack happens if an adversary influences the outcome by carefully choosing the last input, such that the outcome is biased.
This requires that the adversary can see or control the other inputs, and that computing the outcome can be done before the beacon computes it.
    \item[Hijacking Attack]
An adversary can attempt to seize control of the beacon, and operate it to their own benefit.
This could include publishing false results, denying user inputs or not extracting randomness according to protocol, and could potentially violate all properties of the beacon.
For beacons with elected operators, this can be achieved by an adversary, by having themselves elected.

\end{description}
