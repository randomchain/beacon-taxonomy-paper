\subsection{Trusting in Randomness Beacons}
%   Beacon specifications
When considering trust in randomness beacons, we focus on two main perspectives, namely \emph{trust assumptions} and \emph{security objectives}.
These describe what assumptions can be made about the trustworthiness of a randomness beacon from our definition, and what attacks must be considered.
Security and trust are two sides of the same coin, which means that the approach a given beacons takes to handling the security objectives is influenced by and influences the trust assumptions of the beacon.
Not all of these assumptions and attacks will be relevant to all types of beacons, as different types of beacons have different properties in addition to ours.

\subsubsection{Trust Assumptions}\label{ssub:trust_assumptions}
The trust assumptions of a randomness beacon depend on the interaction with, and execution of the beacon, as well as the source of entropy.
The following trust assumptions are from the users' point of view, unless otherwise stated.
A user is anyone with a stake in the outcome of the beacon, both through direct use, but also indirect or inferred usage.
\begin{description}

    \item[Guaranteed Entropy Level]
        Assumptions about the level of entropy in the outcome, rely on the entropy of the input and the properties of the computation which generates the outcome, e.g.\ an extractor function.
        Users must be able to reason about the entropy level of the input source, through documentation or otherwise. One way could be to calculate the Shannon Entropy of the source~\cite{informationtheory} for an average case entropy analysis, or the min-entropy for a strict lower bound on the entropy.
        The entropy source and extractor function must be publicly available, such that users can verify the level of entropy.

    \item[Verifiability]
        For a beacon to display verifiability, a user must be able to verify correct execution of the beacon protocol.
        The input to the beacon must be available for users to verify a given output, unless the beacon is able to produce a proof, which allows users to verify. \msmnote{this could be interesting to expand upon, to allow for anonymized beacon interaction}.

        The most straight forward verification for randomness beacons is for a user to run the same computation on the same input.
However, this may be impractical or the input may be secret, which would require different approaches.
This could include using proofs or functions that can rapidly be verified such as hashing functions~\cite{nakamoto2008bitcoin} or modular square roots~\cite{lenstra2015random}.
        Verifiability can eliminate the need for trust in participants, while ensuring the trustworthiness of the outcome.

    \item[Input Reasoning]
        Being able to reason about the input is coupled to the two previous trust assumptions.
This trust assumption concerns what users can assume about the bias of the input.
        The easier it is for adversaries to bias the input, the easier they can bias the randomness.
        This assumption may also change significantly if the input is purely user-supplied.
As long a given user contributes their own input, the others may not be able to bias the randomness against him.

\end{description}

\stefan{Wouldn't it make sense to discuss here some basic ideas how to achieve these properties, e.g., using protocols like MPC etc, and only then think about attacks? Or, keep the order as it is, but then do not talk about MPC yet in 4.1.2 (OUTDATED? --- msm)}

%       Security objectives
\subsubsection{Attacks}\label{ssub:security_objectives}
For randomness beacons there exist two main venues of attack: \emph{availability} and \emph{integrity}
Each term contains multiple types of attacks and requirements for fulfillment, and will not all be effective versus all beacons different randomness beacon approaches assign different priorities to these.

We identify the following attacks on the availability of a beacon:

\begin{description}
    \item[\Acrfull{dos}] The attacker prevents users from accessing the output by overwhelming the operator with network traffic, or manipulating the network with an eclipse attack~\cite{Singh06eclipseattacks} to prevent certain users from accessing the beacon output.
    \item[Preventing Protocol Execution] Some \gls{mpc} protocols rely on having an honest majority to complete~\cite{cascudo2017scrape} --- an attacker or group of attackers could outnumber the honest parties, preventing the protocol from delivering an output.
    \item[Denial of Input] For beacons that use user input, the attacker can overwhelm the operator with input \stefan{well why not just block the inputs of others directly? (Not sure what he wants here)}, preventing other users from contributing, and potentially biasing the input, violating the unpredictability and randomness properties of the beacon.
    While this does not prevent the beacons output, it prevents users from interacting with the beacon according to protocol, hence why it is classified as an attack on availability.
\end{description}

\noindent%
We also identify the following attacks on the integrity of a beacon:

\begin{description}
    \item[Input Bias Attack] For beacons that use some external public source for input, an adversary can attempt to bias the results by controlling the state of that source, violating the unpredictability of the beacon.
        The difficulty of this type of attack depends on the malleability of the input.
    \item[Last Draw Attack] In beacons using multiple inputs, one of these inputs will be the last input before the beacon generates the output.
        A last draw attack happens if an adversary influences the outcome by carefully choosing the last input.
        This requires that the adversary can see the other inputs, and that computing the outcome can be done before the deadline for input submission.
    \item[Hijacking Attack] For beacons with elected operators, an adversary can attempt to have themselves elected, and then operate the beacon to their own benefit.
        This could include publishing false results, denying user inputs or not extracting randomness according to protocol, and could potentially violate all properties of the beacon. %However, such tampering can be detected if the beacon incorporates some form of verification, which should reveal any divergence from the operating protocol.

\end{description}
