\subsection{Discussion of Rabin's properties}
This section discusses the basic properties for a Randomness Beacon based on Rabin's properties.
After the discussion we motivate the need for a new property, \emph{entropy guarantee}, before we tackle a property that removes the needed trust.
The main idea governing the security of randomness beacon use cases is that the randomness beacon regularly emits a value which is \emph{unpredictable} to all parties.
Rabin's definition of unpredictability is vague, since we do not know what Rabin meant with advance \enquote{knowledge}.
Therefore, we refine unpredictability to mean \enquote{no party should be able to predict the output of the randomness beacon with higher probability than all other parties}.

Unpredictability alone is not enough; imagine a randomness beacon which emits a single unpredictable bit, but with a known distribution to all parties.
For example, it could emit 0 with probability $0.4$ and 1 with probability $0.6$.
This is still unpredictable per the definition that no party is able to predict the output with \emph{higher} probability than other parties, but it is not useful for the use cases because it is biased toward 1 as the output.
It is unclear whether Rabin foresaw this in his definition of unpredictability by including knowledge of the probability distribution in the word \enquote{knowledge}; thus we add our own explicit property, \emph{unbiased}.
Unbiased means that all outputs are equally likely, i.e.\ the output is statistically close to samplings from a uniform distribution. Given that $p(x)$ is the probability of $x$, and $O = \left\{ {o_0, o_1, \ldots, o_n} \right\}$, the set of all possible outcomes, this property can be formalized as:
\[
    \forall o_i \in O \mid p(o_i) \approx \frac{1}{n}
\]

Our definition of unbiased is close to what we believe Rabin meant with random.
However, we do not agree with his emphasis on using a physical method to produce random numbers.
While the randomness of such physical methods are good, they are inherently difficult to trust by users of the randomness beacon.
The reason behind this, is that randomness generated by a physical method only is observable by the entity controlling it.
While the randomness may be good, other parties cannot know if it is unbiased or manipulated.
An unpredictable and unbiased number is inherently random.
Therefore, there is no need to keep Rabin's \emph{random} property.

We relax the requirement of availability to being available in a given setting.
Availability encompasses any way the beacon sources its input and emits its output.
It is not required to be publicly available at all times.
Backups are omitted in our definition because we believe this is an implementation specific detail.

\subsection{Entropy Guarantee}
Rabin is only concerned with emitting integers in a small range, e.g.\ 1--100, because there, for his use cases, is a trade-off between security and time, such that a larger range provides better security but longer transaction times.
However, we do not impose a limit or give suggestions for the range, since it ultimately depends on the use case of the random number.
Some use cases require a larger space of random numbers than other use cases, and therefore it should be known in advance how large this space is.
As such, we need a metric for this measure.
We introduce a property called \emph{Entropy Guarantee}, meaning that it must be possible to guarantee a level of entropy.

Entropy (formally called Shannon entropy) is a measure of information content in a source.
Formally, Shannon Entropy of a source $X$ with alphabet ${a_1, \ldots, a_n}$ and a probability distribution ${p_1, \ldots , p_n}$ where $p_i = p(a_i)$ is defined as~\cite{informationtheory}:
\[
H(X) = -\sum\limits_{i = 1}^n p_{i}\log_{2} p_{i}
\]

As an example, a coin flip has two equally likely outcomes which gives it an entropy of $-\left(\frac{1}{2}\log_2 \frac{1}{2} + \frac{1}{2}\log_2 \frac{1}{2}\right) = 1$.

Since we also have the unbiased property (all outcomes are equally likely), we can simplify this equation significantly. Given that $p(x)$ is the probability of an outcome $x$, the entropy is:
\[
    H(X) = -\log_{2}p(x)
\]

As an example related to randomness beacons, a lottery picking one human on Earth requires at least $-\log_2\left(\frac{1}{7.5~\text{billion}}\right) \approx 33~\text{bits}$ of entropy to be able to express any possible outcome.

\subsection{Removing the Need for Trust}
By now, we have refined \emph{unpredictable} and added \emph{unbiased}.
These two combined makes Rabin's \emph{random} property obsolete.
Moreover we have relaxed \emph{available}, and added \emph{entropy guarantee}.
We believe this is a better definition of properties that a randomness beacon must exhibit --- and will now tackle a property to remove the need for trust.

As previously stated, Rabin's definition requires trust in a third party, with no way of ensuring the honesty of that party.
To avoid the need for blind trust in a third party, we invent a new property with inspiration from \citet{bonneau2015bitcoin}.
Similarly, to our properties, they define unpredictable and unbiased, and also reason about the level of entropy to make sure there is enough.
Their beacon definition is tailored to describe their solution, and as such is not general enough to allow us to borrow it%\footnote{Specifically, they require the input to be unknown before time $t$, and they require that any user can compute the output after time $t$ --- two things that are not necessarily required.}
.

However, they do capture an important element necessary for a \emph{trustless} randomness beacon, namely verifiability --- the ability to verify certain properties of the output.
We adopt the property \emph{verifiability} such that users of the randomness beacon can verify the output. This will be further elaborated in later sections.

\subsection{Formalization}
Since computers are inherently deterministic, a randomness beacon will need to source its random output from somewhere.
The input to a beacon may not be in a directly usable form, and it may require an operation performed on it such that the output adheres to the output specification.
We can regard the input as entropy or a seed to a computation that outputs data with our aforementioned properties.

%A randomness beacon is a service that publishes random data at a known interval.
Formally, let $B: f(I_t) \rightarrow O_t$, where $B$ is a beacon, $I_t$ is the input at time $t$, $O_t$ is the output at time $t$, and $f$ is a suitable function for transforming the input to the output.
For $B$ to be a beacon, it is run at a known, regular interval, $\delta$, such that $t+n\delta$ for any $n \in \mathbb{N}$ are valid output intervals for the beacon.
In \Vref{fig:abstract_beacon} an example of an abstract beacon can be seen.
The green area is what can be defined as the beacon, or \emph{beacon protocol} --- i.e.\ how input is collected, transformed to output and then published.

\subimport{}{simple_beacon_fig.tex}

The function $f$ will likely be an \emph{extractor function}.
Extractor functions can be understood as functions that take an input with a non-uniform distribution and yields a uniformly distributed output.
Informally, they concentrate the entropy level of the input.
Extractor functions require a foundation of entropy as input, i.e.\ they cannot generate randomness from nothing --- they only condense existing entropy.
Common extractor functions have been proven secure when the input has an entropy level of at least $2k$, where $k$ is the number of bits in the output~\cite{dodis2004randomness}.
