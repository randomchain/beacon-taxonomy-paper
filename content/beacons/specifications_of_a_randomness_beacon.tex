\subsection{Trusting in Randomness Beacons}
%   Beacon specifications
When considering trust in randomness beacons, we focus on two main perspectives, namely \emph{trust assumptions} and \emph{security objectives}.
These describe what assumptions can be made about the trustworthiness of a randomness beacon from our properties, and what attacks on those properties must be considered.
Security and trust are two sides of the same coin, which means that the approach a given beacons takes to handling the security objectives is influenced by and influences the trust assumptions of the beacon. Not all of these assumptions and attacks will be relevant to all types of beacons, as different types of beacon have different properties in addition to ours.

\subsubsection{Trust Assumptions}\label{ssub:trust_assumptions}
We can make certain trust assumptions about randomness beacons.
The assumptions depend on the interaction with, and execution of the beacon, as well as the source of entropy of the beacon.
The following trust assumptions are from users' point of view, unless otherwise stated.
A user is anyone with a stake in the outcome of the beacon, both through direct use, but also indirect or inferred usage.
\begin{description}

    \item [Guaranteed Entropy Level:]
        Assumptions about the level of entropy in the outcome, relies on the entropy of the input and the properties of the computation which generates the outcome, e.g.\ an extractor function.
        Users must be able to reason about the entropy level of the input, through documentation or otherwise.
        The entropy source and extractor function must be publicly available, such that users can verify the level of entropy.

    \item [Verifiability:]
        For a beacon to display verifiability, a user must be able to verify correct execution of the beacon protocol.
        The input to the beacon must be available for users to verify a given output, unless the beacon is able to produce a proof, which allows users to verify. \msmnote[nofootnote, inline]{this could be interesting to expand upon, to allow for anonymized beacon interaction}.

        The most straight forward verification for randomness beacons is for a user to run the same computation on the same input.However, this may be impractical or the input may be secret, which would require different approaches. This could include using proofs or functions that can rapidly be verified.

        %An example of verifiability outside beacons is in the blockchain, where the validity of a block can be verified by anyone, using the block itself and a \acrfull{sha}.
        %Here the verifiability removes the need to trust any participating miners in the blockchain.

        Verifiability can eliminate the need for trust in participants, while ensuring the trustworthiness of the outcome.

    \item [Input Reasoning:]
        Being able to reason about the input is coupled to the two previous trust assumptions. This trust assumption concerns what users can assume about the bias of the input.
        The easier it is for adversaries to bias the input, the easier they can bias the randomness.
        This assumption may also change significantly if the input is purely user-supplied. As long a given user contributes their own input, the others will not be able to bias the randomness against him.

        %This mainly relates to beacons where the input is supplied by users, i.e.\ users which do not necessarily trust each other.

        %A given user might not need to worry about the input, even if everybody else is colluding against said user.
        %This is true in a scenario where said user is able to contribute with their own input, and the beacon's computation is fair
        %--- i.e.\ the input of any user cannot affect the outcome differently than other inputs.

\end{description}


%       Security objectives
\subsubsection{Attacks}\label{ssub:security_objectives}
For randomness beacons there exist two main venues of attack: \emph{availability} and \emph{integrity}.
Each term contains multiple types of attacks and requirements for fulfillment, and will not all be effective versus all beacons different randomness beacon approaches assign different priorities to these.

We identify the following attacks on the beacons availability:

\begin{description}
    \item [ \acrfull{dos}] The attacker prevents users from accessing the output by overwhelming the operator with network traffic, or manipulating the network with an eclipse attack to prevent certain users from accessing the beacon output.
    \item [ Preventing Protocol Execution ] Some \gls{mpc} protocols rely on having an honest majority to complete - an attacker or group of attackers could outnumber the honest parties, preventing the protocol from delivering an output.
    \item [ Denial of Input ] For beacons that use user input, the attacker can overwhelm the operator with input, preventing other users from contributing, and potentially biasing the input, violating the unpredictability and randomness properties of the beacon. While this does not prevent the beacons output, it prevents users from interacting with the beacon according to protocol, hence why it is classified as an attack on availability.
\end{description}

We also identify the following attack on the beacons integrity:

\begin{description}
    \item [ Input Bias Attack ] For beacons that use som external public source for input, an adversary can attempt to bias the results by controlling the state of that source, violating the unpredictability of the beacon. The difficulty of this type of attack depends on the malleability of the input.
    \item [ Last Draw Attack ] For beacons that have use user input, an adversary can attempt to commit an input that will bias the randomness towards him as the last user to contribute, ensuring it will not be changed before it is posted. This attack relies on the adversarys ability to precompute the randomness extracted from current adversaries, and how to bias it towards himself. This attack violates the beacons unpredictability.
    \item [ Hijacking Attack ] For beacons with elected operators, an adversary can attempt to have themselves elected, and then operate the beacon to their own benefit. This could include publishing false results, denying user inputs or not extracting randomness according to protocol, and could potentially violate all properties of the beacon. However, such tampering can be detected if the beacon incorporates some form of verification, which should reveal any divergence from the operating protocol.

\end{description}
%\paragraph{Availability:}
%        Attacks on the availability essentially prevent a set of %users from being able to gain access to a given randomness %beacon.
%        This can be both their ability to contribute with input, or %discover the output.
%        In scenarios where the beacon is driven by a single entity, %attacking the availability can also mean preventing the %beacon from collecting input or publishing the outcome, %thereby effectively denying service for all potential users.
%        Besides attacks, bugs in the implementation or network %failures can result in degraded availability;
%        generally these vulnerabilities are present in the same %scenarios as direct attacks.
%        Therefore, a randomness beacon prioritizing availability, %can choose to focus on robustness, redundancy, and failover, %to mitigate failures and attacks on availability.
%
%        An example of concrete attacks on the availability of a %randomness beacon is a
%        \acrfull{dos} where an attacker overwhelms the beacon with %e.g.\ input, thereby making any other user unable to supply %entropy as input. A \gls{dos} attack can also be on the %availability of the source of input itself. Another example %is an eclipse attack where an attacker eclipses a part of %the network, thus only making the beacon unavailable to some %select users.
%
%    \paragraph{Integrity:}
%        The integrity of a randomness beacon determines whether a %given user should trust the outcome and to what degree.
%        Attacking the integrity is therefore any attack which %compromises the outcome of a randomness beacon.
%        This can mean manipulating the input/entropy to the beacon, %but also compromising the entire computation and outcome;
%        as beacons can be seen as entities and not a particular %actor, one might imagine a scenario where an attacker %imposes themselves as the beacon.
%        As with availability, the integrity can also be influenced %by bugs in the implementation.
%        Moreover, if the implementation is closed sources or %proprietary, the beacon loses transparency and the integrity %will be questionable at best.
%
%        An attacks on the integrity could be successfully supplying %valid input, which is able to bias the outcome, e.g.\ last %draw attacks, where an adversary supplies the last input and %therefore potentially is able to choose some input %beneficial to them. Another example is
%        if the operator of the beacon is malicious, they might be %able to generate a seemingly fair and random outcome by %corrupting the computation of the beacon.
%
%        The integrity also relies on the beacon being unpredictable, %i.e.\ no one should be able to predict the outcome before it %is too late to manipulate it.
%        Finally, integrity also embodies the fact that the outcome %should be unbiased and uniformly distributed --- any %detectable statistical bias should be negligible. A %well-chosen extractor function will provide this.
%
%       Trust assumptions


