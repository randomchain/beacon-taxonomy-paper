% Randomness beacons
\section{Randomness Beacons}\label{sec:beacons}
%   What is a beacon?

As part of the goal of this paper, we model attributes a trustworthy randomness beacon must exhibit.
We will also provide a brief understanding of the concept of randomness as it is used within the paper. 
These attributes need to be sufficiently general to encompass a variety of implementations.
However before doing so, we will draw inspiration from earlier definitions.

\subsection{Randomness}\label{sub:beacons_randomness}
\stefan{this subsection is not very comprehensive (nor comprehnsible): step back a bit more and think what really needs to be said here (which will also be relevant later)}

Intuitively speaking randomness is a lack of predictability in events or information. It can also be thought of as data sampled from a uniform distribution, where any sample is as likely as another. The unpredictability of a source of information is measured in entropy.
We define a source of information as a stream of information based on some real-world occurrence. This can be direct input from users or observation of some external system --- the important aspect is that the source continually produces fresh information.  
Within information theory, Shannon Entropy is defined as the unpredictability of a state. As an example, a coinflip has two equally likely outcomes that can not be predicted ahead of time, and has an entropy of $\log_{2} 2 = 1$ bit~\cite{informationtheory}. 
Formally Shannon Entropy of a b-nary source $X$ with alphabet ${a_1, a_2, \ldots, a_n}$ and a probability distribution ${p_1, \ldots , p_n}$ where $p_i = p(a_i)$ is defined as  $\eta_{b} (X) = \sum\limits_{i = 1}^n p_{i}\log_{b} p_{i}$~\cite{informationtheory}. 
Likewise, a lower bound on the entropy, the  min-entropy, can be calculated as follows: $\eta _\infty(X) _{b} = -\log_{b}(\max(p(x)))$ \cite{informationtheory} .

High levels of entropy makes it hard to predict the data produced by the source, and can be obtained from data with less entropy by using extractor functions~\cite{pseudorandomness}. Extractor functions can be understood as functions that take a large input with little entropy spread throughout the input, and concentrates it into a smaller output. They extract the entropy, measuring unpredictability, from the larger input and concentrates it into the output. 

\citet{bonneau2015bitcoin} define an extractor function as $y = \text{Ext}_k(x)$.
An extractor $\text{Ext}$ is applied on an $n$-bit input $x$ of \enquote{sufficient} entropy.
The output $y$ is $m$ bits of \enquote{high} entropy, where $m < n$. The key $k$ is used to select from a family of extractors.
They further define \enquote{sufficient} to be that the min-entropy is at least $m$ bits, and \enquote{high} entropy to be that there is only an negligible difference between the output $y$ and an $m$-bit uniform distribution.
As such, it is able to convert weak random sources into a highly random output, that statistically appears to be uniformly distributed.

\subsection{Beacons}

The term \emph{beacon} was originally introduced by \citet{rabin1983transaction}, who describes it as a trusted third party that emits random numbers at a set interval as a way to enable fair contract signing and secret disclosure.
He assumes that beacon is provided as a service by a trusted third party and behaves \enquote{honestly}.
He furthermore argues for a number of criteria for the beacon:

\begin{description}
    \item[Unpredictability] No party should be able to have advance knowledge of the beacons messages.
    \item[Random] The beacon should use some physical method to produce random numbers.
    \item[Availability] The beacon should be publicly available, and could have backups in case of failure or jamming.
\end{description}

As stated, this definition requires trust in a third party, with no way to ensure the honesty of that party and closely matches the \gls{nist} randomness beacon.
Since we do not want to trust blindly in a third party, we will look for an alternative definition.

\citet{bonneau2015bitcoin} extends this description to describe a decentralized beacon based on the bitcoin blockchain.
It is a function that returns an $m$-bit near-uniformly distributed random value $r$ at each time interval $t$.
An assumption on the min-entropy of the input is made. \citet{dodis2004randomness} define min-entropy as the minimum integer $m$ such that for all bit strings $x$ in a probability distribution $\chi$, $\text{Pr}_\chi(x) \leq 2^{-m}$.
In other words, it is the least amount of bits required to describe the worst-case output.
Therefore it is a conservative way of measuring unpredictability.

The $m$-bit value is computed from a sample of the source at time $t$, $D_t$, using an extractor function. \stefan{give some intuition what is hard about making it decentralized(What even is this, should it be fixed? - S) }

They describe a beacon as a function applied regularly to some input with a known min-entropy.
They capture an element necessary for a trustless randomness beacon, namely verifiability --- the ability to verify certain properties of the output.
They also differ in the requirement on randomness, as the output must simply be statistically close to uniform random string.

Their beacon definition is, however, tailored to describe their solution, and is as such not broad enough to allow for other solutions.
Specifically, they require the input to be unknown before time $t$, and they require that any user can compute the output after time $t$ --- two things that are not necessarily required in some solutions.

\stefan{are these two papers the only ones that matter? otherwise list all the other papers too and put them in some categories}

We therefore synthesize our own definition, which will be used forward in this paper:

A  randomness beacon is a service that publishes random data at a known interval.
Formally, let $B: f(I_t) \rightarrow R$, where $B$ is a beacon, $I_t$ is the input at time $t$, $f$ is a suitable function for generating randomness (such as an extractor function), and $R$ is the random outcome. The entropy of $R$ depends on the quality of $I$, and $I$ can consist of observations of some external source or be directly input by users that use the beacon. 
For $B$ to be a beacon, it is run at a known, regular interval, $\delta$, such that $t+n\delta$ for any $n \in \mathbb{N}$ are output intervals for the beacon.

This can also be considered the \emph{beacon protocol}, the procedure that guides the beacons operations. The protocol also dictates how users interact with the beacon, and how it is controlled. The protocol is enforced by a \emph{beacon operator} that controls the beacon, or algorithmically. 

%It is, however, difficult to quantify these qualities without making assumptions on the function $f$ or assumptions about the applications using the output of the beacon --- we will therefore not require a quantity, but rather allow for reasoning about the quality of a given beacon.


To describe a randomness beacon, we present the following attributes.
Each of these attributes may or may not be fulfilled to some degree --- however an ideal trustworthy randomness beacon should have all of these attributes. As an absolute minimum, a beacon must be unpredictable and have some level of min-entropy. It must also be available, but does not always need to be this - periodic availability could be sufficient for some usecases. Verifiability is only required if users do not want to trust the beacon, it could easily function without it. 

\begin{description}
    \item[Unpredictable]
        Any user should not be able to predict any information about the output of the beacon prior to time $t$ --- or more precisely, a user should not be able to predict the output with a larger probability than sampling a uniform distribution.
        This indirectly also makes the beacon unmanipulatable, as manipulation would lead to some degree of predictability for some user(s).
    \item[Entropy Reasoning]
		The output must provide some guarantees on the level of entropy, such as a lower bound or min-entropy of the input source.
        This is a way of guaranteeing some level of randomness.
    \item[Availability]
        All users in a given setting should have access to the randomness beacon.
        This means both their ability to contribute with input, if applicable, and their access to the output.
    \item[Verifiability]
        Users should not need to trust \emph{any} output.
        A beacon needs to be designed such that it can prove its honesty instead of requiring blind trust.
        This proof can for example be accompanying the output with a proof that can be used to verify the correctness of the output, or giving the users to ability to contest the correctness of the output.
\end{description}

This definition is more flexible than the predecessors, as it does not require a randomness beacon to be publicly available, but rather introduces a \emph{setting} since beacons could also see use in non-public settings.
However, it also poses a more strict definition of correctness, since it must be proved.
%It also generalizes the verifiability to simply concern the honesty of the beacon.

The definition does not specify any properties about interaction, security, or execution of the beacon and its protocol --- only that it somehow has to prove its honesty.
These properties rely on the setting and requirements of a given beacon.
